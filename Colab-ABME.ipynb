{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-ABME.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQy61byYFdKX"
      },
      "source": [
        "# Colab-ABME\n",
        "\n",
        "Original repo: [JunHeum/ABME](https://github.com/JunHeum/ABME)\n",
        "\n",
        "My fork: [styler00dollar/Colab-ABME](https://github.com/styler00dollar/Colab-ABME)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHoHhFVk1CeU"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Zx0BZZP2GL9w"
      },
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('Google Drive connected.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMaEc9CJzxly",
        "cellView": "form"
      },
      "source": [
        "#@title install\n",
        "%cd /content/\n",
        "!git clone https://github.com/JunHeum/ABME\n",
        "!gdown --id 1fRLxZ0rYjto2yI1nHuUQ1-OsNkYqq-mL\n",
        "!7z e /content/ABME_Weights.zip\n",
        "%cd /content/ABME/correlation_package\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-myM_sWYM9dU"
      },
      "source": [
        "#@title get video / copy it into the cainapp folder\n",
        "%cd /content\n",
        "# either copy video from drive \n",
        "#!cp /path/ /path/\n",
        "\n",
        "#or get one with wget / youtube-dl\n",
        "# wget\n",
        "#!wget URL\n",
        "\n",
        "# youtube-dl\n",
        "!sudo rm -rf test.mp4\n",
        "!wget -O - https://yt-dl.org/latest/youtube-dl | sudo tee /usr/local/bin/youtube-dl > /dev/null\n",
        "!sudo chmod a+x /usr/local/bin/youtube-dl\n",
        "video_path = \"/content/test.mp4\"\n",
        "!youtube-dl \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" --output {video_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQjRM6mH2I0R"
      },
      "source": [
        "# extract data\n",
        "# adjust rescale value if needed, or remove it\n",
        "!mkdir /content/data\n",
        "input_path = \"/content/test.mkv\" #@param\n",
        "%shell ffmpeg -i {input_path} -vf scale=848:480:flags=lanczos \"/content/data/%05d.png\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "1yRB1yRwQn1c"
      },
      "source": [
        "#@title SynthesisNet.py (forcing DDP Off)\n",
        "%%writefile /content/ABME/model/SynthesisNet.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class DynFilter(nn.Module):\n",
        "    def __init__(self, kernel_size=(3,3), padding=1, DDP=False):\n",
        "        super(DynFilter, self).__init__()\n",
        "\n",
        "        self.padding = padding\n",
        "        \n",
        "        filter_localexpand_np = np.reshape(np.eye(np.prod(kernel_size), np.prod(kernel_size)), (np.prod(kernel_size), 1, kernel_size[0], kernel_size[1]))\n",
        "        if DDP:\n",
        "            self.register_buffer('filter_localexpand', torch.FloatTensor(filter_localexpand_np)) # for DDP model\n",
        "        else:\n",
        "            self.filter_localexpand = torch.FloatTensor(filter_localexpand_np).cuda() # for single model\n",
        "\n",
        "    def forward(self, x, filter):\n",
        "        x_localexpand = []\n",
        "\n",
        "        for c in range(x.size(1)):\n",
        "            x_localexpand.append(F.conv2d(x[:, c:c + 1, :, :], self.filter_localexpand, padding=self.padding))\n",
        "\n",
        "        x_localexpand = torch.cat(x_localexpand, dim=1)\n",
        "        x = torch.sum(torch.mul(x_localexpand, filter), dim=1).unsqueeze(1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Feature_Pyramid(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Feature_Pyramid, self).__init__()\n",
        "\n",
        "        self.Feature_First = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.PReLU())\n",
        "\n",
        "        self.Feature_Second = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.PReLU())\n",
        "\n",
        "        self.Feature_Third = nn.Sequential(\n",
        "            nn.Conv2d(64, 96, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.PReLU())\n",
        "\n",
        "    def forward(self, Input):\n",
        "        Feature_1 = self.Feature_First(Input)\n",
        "        Feature_2 = self.Feature_Second(Feature_1)\n",
        "        Feature_3 = self.Feature_Third(Feature_2)\n",
        "\n",
        "        return Feature_1, Feature_2, Feature_3\n",
        "\n",
        "\n",
        "class GridNet_Filter(nn.Module):\n",
        "    def __init__(self, output_channel):\n",
        "        super(GridNet_Filter, self).__init__()\n",
        "\n",
        "        def First(intInput, intOutput):\n",
        "            return torch.nn.Sequential(\n",
        "                torch.nn.Conv2d(in_channels=intInput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1)),\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intOutput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1))\n",
        "            )\n",
        "\n",
        "        def lateral(intInput, intOutput):\n",
        "            return torch.nn.Sequential(\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intInput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1)),\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intOutput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1))\n",
        "            )\n",
        "\n",
        "        def downsampling(intInput, intOutput):\n",
        "            return torch.nn.Sequential(\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intInput, out_channels=intOutput, kernel_size=(3, 3), stride=(2, 2),\n",
        "                                padding=(1, 1)),\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intOutput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1)),\n",
        "            )\n",
        "\n",
        "        def upsampling(intInput, intOutput):\n",
        "            return torch.nn.Sequential(\n",
        "                torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intInput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1)),\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intOutput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1)),\n",
        "            )\n",
        "\n",
        "        def Last(intInput, intOutput):\n",
        "            return torch.nn.Sequential(\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intInput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1)),\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intOutput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1))\n",
        "            )\n",
        "\n",
        "        self.First_Block = First(4 * (3+32), 32)  # 4*RGB(3) + 4* 1st features(32)\n",
        "\n",
        "        self.Row1_1 = lateral(32, 32)\n",
        "        self.Row1_2 = lateral(32, 32)\n",
        "        self.Row1_3 = lateral(32, 32)\n",
        "        self.Row1_4 = lateral(32, 32)\n",
        "        self.Row1_5 = lateral(32, 32)\n",
        "        self.Last_Block = Last(32, output_channel) \n",
        "\n",
        "        self.Row2_0 = First(4 * 64, 64)\n",
        "\n",
        "        self.Row2_1 = lateral(64, 64)  \n",
        "        self.Row2_2 = lateral(64, 64)\n",
        "        self.Row2_3 = lateral(64, 64)\n",
        "        self.Row2_4 = lateral(64, 64)\n",
        "        self.Row2_5 = lateral(64, 64)\n",
        "\n",
        "        self.Row3_0 = First(4 * 96, 96)\n",
        "\n",
        "        self.Row3_1 = lateral(96, 96)  \n",
        "        self.Row3_2 = lateral(96, 96)\n",
        "        self.Row3_3 = lateral(96, 96)\n",
        "        self.Row3_4 = lateral(96, 96)\n",
        "        self.Row3_5 = lateral(96, 96)\n",
        "\n",
        "        self.Col1_1 = downsampling(32, 64)\n",
        "        self.Col2_1 = downsampling(64, 96)\n",
        "        self.Col1_2 = downsampling(32, 64)\n",
        "        self.Col2_2 = downsampling(64, 96)\n",
        "        self.Col1_3 = downsampling(32, 64)\n",
        "        self.Col2_3 = downsampling(64, 96)\n",
        "\n",
        "        self.Col1_4 = upsampling(64, 32)\n",
        "        self.Col2_4 = upsampling(96, 64)\n",
        "        self.Col1_5 = upsampling(64, 32)\n",
        "        self.Col2_5 = upsampling(96, 64)\n",
        "        self.Col1_6 = upsampling(64, 32)\n",
        "        self.Col2_6 = upsampling(96, 64)\n",
        "\n",
        "    def forward(self, V_0_t_SBM, V_0_t_ABM, V_1_t_SBM, V_1_t_ABM):\n",
        "        Variable1_1 = self.First_Block(torch.cat((V_0_t_SBM[0], V_0_t_ABM[0], V_1_t_SBM[0], V_1_t_ABM[0]), dim=1))  # 1\n",
        "        Variable1_2 = self.Row1_1(Variable1_1) + Variable1_1  # 2\n",
        "        Variable1_3 = self.Row1_2(Variable1_2) + Variable1_2  # 3\n",
        "\n",
        "        Variable2_0 = self.Row2_0(torch.cat((V_0_t_SBM[1][:, 3:, :, :], V_0_t_ABM[1][:, 3:, :, :], V_1_t_SBM[1][:, 3:, :, :], V_1_t_ABM[1][:, 3:, :, :]), dim=1))  # 4\n",
        "        Variable2_1 = self.Col1_1(Variable1_1) + Variable2_0  # 5\n",
        "        Variable2_2 = self.Col1_2(Variable1_2) + self.Row2_1(Variable2_1) + Variable2_1  # 6\n",
        "        Variable2_3 = self.Col1_3(Variable1_3) + self.Row2_2(Variable2_2) + Variable2_2  # 7\n",
        "\n",
        "        Variable3_0 = self.Row3_0(torch.cat((V_0_t_SBM[2][:, 3:, :, :], V_0_t_ABM[2][:, 3:, :, :], V_1_t_SBM[2][:, 3:, :, :], V_1_t_ABM[2][:, 3:, :, :]), dim=1))  # 8\n",
        "        Variable3_1 = self.Col2_1(Variable2_1) + Variable3_0  # 9\n",
        "        Variable3_2 = self.Col2_2(Variable2_2) + self.Row3_1(Variable3_1) + Variable3_1  # 10\n",
        "        Variable3_3 = self.Col2_3(Variable2_3) + self.Row3_2(Variable3_2) + Variable3_2  # 11\n",
        "\n",
        "        Variable3_4 = self.Row3_3(Variable3_3) + Variable3_3  # 10\n",
        "        Variable3_5 = self.Row3_4(Variable3_4) + Variable3_4  # 11\n",
        "        Variable3_6 = self.Row3_5(Variable3_5) + Variable3_5  # 12\n",
        "\n",
        "        Variable2_4 = self.Col2_4(Variable3_4) + self.Row2_3(Variable2_3) + Variable2_3  # 13\n",
        "        Variable2_5 = self.Col2_5(Variable3_5) + self.Row2_4(Variable2_4) + Variable2_4  # 14\n",
        "        Variable2_6 = self.Col2_6(Variable3_6) + self.Row2_5(Variable2_5) + Variable2_5  # 15\n",
        "\n",
        "        Variable1_4 = self.Col1_4(Variable2_4) + self.Row1_3(Variable1_3) + Variable1_3  # 16\n",
        "        Variable1_5 = self.Col1_5(Variable2_5) + self.Row1_4(Variable1_4) + Variable1_4  # 17\n",
        "        Variable1_6 = self.Col1_6(Variable2_6) + self.Row1_5(Variable1_5) + Variable1_5  # 18\n",
        "\n",
        "        return self.Last_Block(Variable1_6)  # 19\n",
        "\n",
        "\n",
        "class GridNet_Refine(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GridNet_Refine, self).__init__()\n",
        "\n",
        "        def First(intInput, intOutput):\n",
        "            return torch.nn.Sequential(\n",
        "                torch.nn.Conv2d(in_channels=intInput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1)),\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intOutput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1))\n",
        "            )\n",
        "\n",
        "        def lateral(intInput, intOutput):\n",
        "            return torch.nn.Sequential(\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intInput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1)),\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intOutput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1))\n",
        "            )\n",
        "\n",
        "        def downsampling(intInput, intOutput):\n",
        "            return torch.nn.Sequential(\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intInput, out_channels=intOutput, kernel_size=(3, 3), stride=(2, 2),\n",
        "                                padding=(1, 1)),\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intOutput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1)),\n",
        "            )\n",
        "\n",
        "        def upsampling(intInput, intOutput):\n",
        "            return torch.nn.Sequential(\n",
        "                torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intInput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1)),\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intOutput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1)),\n",
        "            )\n",
        "\n",
        "        def Last(intInput, intOutput):\n",
        "            return torch.nn.Sequential(\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intInput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1)),\n",
        "                torch.nn.PReLU(),\n",
        "                torch.nn.Conv2d(in_channels=intOutput, out_channels=intOutput, kernel_size=(3, 3), stride=(1, 1),\n",
        "                                padding=(1, 1))\n",
        "            )\n",
        "\n",
        "        self.First_Block = First(3 + 32 + 4 * 32, 32)\n",
        "\n",
        "        self.Row1_1 = lateral(32, 32)\n",
        "        self.Row1_2 = lateral(32, 32)\n",
        "        self.Row1_3 = lateral(32, 32)\n",
        "        self.Row1_4 = lateral(32, 32)\n",
        "        self.Row1_5 = lateral(32, 32)\n",
        "        self.Last_Block = Last(32, 3)\n",
        "\n",
        "        self.Row2_0 = First(4 * 64, 64)\n",
        "\n",
        "        self.Row2_1 = lateral(64, 64)\n",
        "        self.Row2_2 = lateral(64, 64)\n",
        "        self.Row2_3 = lateral(64, 64)\n",
        "        self.Row2_4 = lateral(64, 64)\n",
        "        self.Row2_5 = lateral(64, 64)\n",
        "\n",
        "        self.Row3_0 = First(4 * 96, 96)\n",
        "\n",
        "        self.Row3_1 = lateral(96, 96)\n",
        "        self.Row3_2 = lateral(96, 96)\n",
        "        self.Row3_3 = lateral(96, 96)\n",
        "        self.Row3_4 = lateral(96, 96)\n",
        "        self.Row3_5 = lateral(96, 96)\n",
        "\n",
        "        self.Col1_1 = downsampling(32, 64)\n",
        "        self.Col2_1 = downsampling(64, 96)\n",
        "        self.Col1_2 = downsampling(32, 64)\n",
        "        self.Col2_2 = downsampling(64, 96)\n",
        "        self.Col1_3 = downsampling(32, 64)\n",
        "        self.Col2_3 = downsampling(64, 96)\n",
        "\n",
        "        self.Col1_4 = upsampling(64, 32)\n",
        "        self.Col2_4 = upsampling(96, 64)\n",
        "        self.Col1_5 = upsampling(64, 32)\n",
        "        self.Col2_5 = upsampling(96, 64)\n",
        "        self.Col1_6 = upsampling(64, 32)\n",
        "        self.Col2_6 = upsampling(96, 64)\n",
        "\n",
        "    def forward(self, V_t, V_SBM_bw, V_ABM_bw, V_SBM_fw, V_ABM_fw):\n",
        "        Variable1_1 = self.First_Block(torch.cat((V_t, V_SBM_bw[0][:, 3:, :, :], V_ABM_bw[0][:, 3:, :, :], V_SBM_fw[0][:, 3:, :, :], V_ABM_fw[0][:, 3:, :, :]), dim=1))  # 1\n",
        "        Variable1_2 = self.Row1_1(Variable1_1) + Variable1_1  # 2\n",
        "        Variable1_3 = self.Row1_2(Variable1_2) + Variable1_2  # 3\n",
        "\n",
        "        Variable2_0 = self.Row2_0(torch.cat((V_SBM_bw[1][:, 3:, :, :], V_ABM_bw[1][:, 3:, :, :], V_SBM_fw[1][:, 3:, :, :], V_ABM_fw[1][:, 3:, :, :]), dim=1))  # 4\n",
        "        Variable2_1 = self.Col1_1(Variable1_1) + Variable2_0  # 5\n",
        "        Variable2_2 = self.Col1_2(Variable1_2) + self.Row2_1(Variable2_1) + Variable2_1  # 6\n",
        "        Variable2_3 = self.Col1_3(Variable1_3) + self.Row2_2(Variable2_2) + Variable2_2  # 7\n",
        "\n",
        "        Variable3_0 = self.Row3_0(torch.cat((V_SBM_bw[2][:, 3:, :, :], V_ABM_bw[2][:, 3:, :, :], V_SBM_fw[2][:, 3:, :, :], V_ABM_fw[2][:, 3:, :, :]), dim=1))  # 8\n",
        "        Variable3_1 = self.Col2_1(Variable2_1) + Variable3_0  # 9\n",
        "        Variable3_2 = self.Col2_2(Variable2_2) + self.Row3_1(Variable3_1) + Variable3_1  # 10\n",
        "        Variable3_3 = self.Col2_3(Variable2_3) + self.Row3_2(Variable3_2) + Variable3_2  # 11\n",
        "\n",
        "        Variable3_4 = self.Row3_3(Variable3_3) + Variable3_3  # 12\n",
        "        Variable3_5 = self.Row3_4(Variable3_4) + Variable3_4  # 13\n",
        "        Variable3_6 = self.Row3_5(Variable3_5) + Variable3_5  # 14\n",
        "\n",
        "        Variable2_4 = self.Col2_4(Variable3_4) + self.Row2_3(Variable2_3) + Variable2_3  # 15\n",
        "        Variable2_5 = self.Col2_5(Variable3_5) + self.Row2_4(Variable2_4) + Variable2_4  # 16\n",
        "        Variable2_6 = self.Col2_6(Variable3_6) + self.Row2_5(Variable2_5) + Variable2_5  # 17\n",
        "\n",
        "        Variable1_4 = self.Col1_4(Variable2_4) + self.Row1_3(Variable1_3) + Variable1_3  # 18\n",
        "        Variable1_5 = self.Col1_5(Variable2_5) + self.Row1_4(Variable1_4) + Variable1_4  # 19\n",
        "        Variable1_6 = self.Col1_6(Variable2_6) + self.Row1_5(Variable1_5) + Variable1_5  # 20\n",
        "\n",
        "        return self.Last_Block(Variable1_6)  # 21\n",
        "\n",
        "\n",
        "class SynthesisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SynthesisNet, self).__init__()\n",
        "        \n",
        "        self.ctxNet = Feature_Pyramid()\n",
        "\n",
        "        self.FilterNet = GridNet_Filter(3 * 3 * 4)\n",
        "\n",
        "        self.RefineNet = GridNet_Refine()\n",
        "        \n",
        "        self.Filtering = DynFilter(kernel_size=(3,3), padding=1, DDP=False)\n",
        "\n",
        "    def warp(self, x, flo):\n",
        "        B, C, H, W = x.size()\n",
        "        # mesh grid\n",
        "        xx = torch.arange(0, W).view(1, 1, 1, W).expand(B, 1, H, W)\n",
        "        yy = torch.arange(0, H).view(1, 1, H, 1).expand(B, 1, H, W)\n",
        "\n",
        "        grid = torch.cat((xx, yy), 1).float().to(x.device)\n",
        "\n",
        "        vgrid = torch.autograd.Variable(grid) + flo\n",
        "\n",
        "        # scale grid to [-1,1]\n",
        "        vgrid[:, 0, :, :] = 2.0 * vgrid[:, 0, :, :] / max(W - 1, 1) - 1.0\n",
        "        vgrid[:, 1, :, :] = 2.0 * vgrid[:, 1, :, :] / max(H - 1, 1) - 1.0\n",
        "\n",
        "        vgrid = vgrid.permute(0, 2, 3, 1)\n",
        "        output = nn.functional.grid_sample(x, vgrid, align_corners=True)\n",
        "        mask = torch.autograd.Variable(torch.ones(x.size())).to(x.device)\n",
        "        mask = nn.functional.grid_sample(mask, vgrid, align_corners=True)\n",
        "\n",
        "        mask = mask.masked_fill_(mask < 0.999, 0)\n",
        "        mask = mask.masked_fill_(mask > 0, 1)\n",
        "\n",
        "        return output * mask\n",
        "\n",
        "    def Flow_pyramid(self, flow):\n",
        "        flow_pyr = []\n",
        "        flow_pyr.append(flow)\n",
        "        for i in range(1, 3):\n",
        "            flow_pyr.append(F.interpolate(flow, scale_factor=0.5 ** i, mode='bilinear') * (0.5 ** i))\n",
        "        return flow_pyr\n",
        "\n",
        "    def Img_pyramid(self, Img):\n",
        "        img_pyr = []\n",
        "        img_pyr.append(Img)\n",
        "        for i in range(1, 3):\n",
        "            img_pyr.append(F.interpolate(Img, scale_factor=0.5 ** i, mode='bilinear'))\n",
        "        return img_pyr\n",
        "\n",
        "    def forward(self, input, time_step=0.5):\n",
        "        I0 = input[:, :3, :, :]  # First frame\n",
        "        I1 = input[:, 3:6, :, :]  # Second frame\n",
        "        SBM_t_1 = input[:, 6:8, :, :]  \n",
        "        SBM_Pyr_t_1 = self.Flow_pyramid(SBM_t_1)\n",
        "        ABM_t_1 = input[:, 8:10, :, :] \n",
        "        ABM_t_0 = input[:, 10:12, :, :]\n",
        "        \n",
        "        ABM_Pyr_t_0 = self.Flow_pyramid(ABM_t_0)\n",
        "        ABM_Pyr_t_1 = self.Flow_pyramid(ABM_t_1)\n",
        "\n",
        "        V_Pyr_0 = self.ctxNet(I0)  # Feature pyramid of first frame\n",
        "        V_Pyr_1 = self.ctxNet(I1)  # Feature pyramid of second frame\n",
        "\n",
        "        I_Pyr_0 = self.Img_pyramid(I0)\n",
        "        I_Pyr_1 = self.Img_pyramid(I1)\n",
        "\n",
        "        V_Pyr_0_t_SBM = []\n",
        "        V_Pyr_1_t_SBM = []\n",
        "        V_Pyr_0_t_ABM = []\n",
        "        V_Pyr_1_t_ABM = []\n",
        "\n",
        "        for i in range(3):\n",
        "            V_0_t_SBM = self.warp(torch.cat((I_Pyr_0[i], V_Pyr_0[i]), dim=1), SBM_Pyr_t_1[i] * (-1))\n",
        "            V_0_t_ABM = self.warp(torch.cat((I_Pyr_0[i], V_Pyr_0[i]), dim=1), ABM_Pyr_t_0[i])\n",
        "\n",
        "            V_1_t_SBM = self.warp(torch.cat((I_Pyr_1[i], V_Pyr_1[i]), dim=1), SBM_Pyr_t_1[i])\n",
        "            V_1_t_ABM = self.warp(torch.cat((I_Pyr_1[i], V_Pyr_1[i]), dim=1), ABM_Pyr_t_1[i])\n",
        "\n",
        "            V_Pyr_0_t_SBM.append(V_0_t_SBM)\n",
        "            V_Pyr_0_t_ABM.append(V_0_t_ABM)\n",
        "\n",
        "            V_Pyr_1_t_SBM.append(V_1_t_SBM)\n",
        "            V_Pyr_1_t_ABM.append(V_1_t_ABM)\n",
        "\n",
        "        DF = F.softmax(self.FilterNet(V_Pyr_0_t_SBM, V_Pyr_0_t_ABM, V_Pyr_1_t_SBM, V_Pyr_1_t_ABM), dim=1)\n",
        "        \n",
        "        Filtered_input = []\n",
        "        for i in range(V_Pyr_0_t_SBM[0].size(1)):\n",
        "            Filtered_input.append(self.Filtering(torch.cat((V_Pyr_0_t_SBM[0][:, i:i + 1, :, :], V_Pyr_0_t_ABM[0][:, i:i + 1, :, :],\n",
        "                                                            V_Pyr_1_t_SBM[0][:, i:i + 1, :, :], V_Pyr_1_t_ABM[0][:, i:i + 1, :, :]), dim=1), DF))\n",
        "\n",
        "        Filtered_t = torch.cat(Filtered_input, dim=1)\n",
        "\n",
        "        R_t = self.RefineNet(Filtered_t, V_Pyr_0_t_SBM, V_Pyr_0_t_ABM, V_Pyr_1_t_SBM, V_Pyr_1_t_ABM)\n",
        "\n",
        "        output = Filtered_t[:, :3, :, :] + R_t\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgBcbIaqLwNn",
        "cellView": "form"
      },
      "source": [
        "#@title gpu inference\n",
        "%cd /content/ABME\n",
        "from types import FrameType\n",
        "from math import ceil\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import warnings\n",
        "import numpy\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "from model import SBMENet, ABMRNet, SynthesisNet\n",
        "from skimage.io import imread\n",
        "from torchvision.utils import save_image\n",
        "from utils import warp\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "frames_dir = \"/content/data\" #@param\n",
        "files = sorted(glob.glob(frames_dir + '/**/*.png', recursive=True))\n",
        "del files[-1]\n",
        "\n",
        "SBMNet = SBMENet()\n",
        "ABMNet = ABMRNet()\n",
        "SynNet = SynthesisNet()\n",
        "\n",
        "SBMNet.load_state_dict(torch.load('/content/SBME_ckpt.pth', map_location='cpu'))\n",
        "ABMNet.load_state_dict(torch.load('/content/ABMR_ckpt.pth', map_location='cpu'))\n",
        "SynNet.load_state_dict(torch.load('/content/SynNet_ckpt.pth', map_location='cpu'))\n",
        "\n",
        "for param in SBMNet.parameters():\n",
        "    param.requires_grad = False \n",
        "for param in ABMNet.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in SynNet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "SBMNet.cuda()\n",
        "ABMNet.cuda()\n",
        "SynNet.cuda()\n",
        "\n",
        "input_frame = 1\n",
        "for f in tqdm(files):\n",
        "  with torch.no_grad():\n",
        "    filename_frame_1 = f\n",
        "    filename_frame_2 = os.path.join(frames_dir, f'{input_frame+1:0>5d}.png')\n",
        "    output_frame_file_path = os.path.join(frames_dir, f\"{input_frame:0>5d}_0.5.png\")\n",
        "\n",
        "    frame1 = TF.to_tensor(imread(filename_frame_1)).unsqueeze(0).cuda()\n",
        "    frame3 = TF.to_tensor(imread(filename_frame_2)).unsqueeze(0).cuda()\n",
        "\n",
        "    H = frame1.shape[2]\n",
        "    W = frame1.shape[3]\n",
        "\n",
        "    # 4K video requires GPU memory of more than 24GB. We recommend crop it into 4 regions with some margin.\n",
        "    if H < 512:\n",
        "        divisor = 64.\n",
        "        D_factor = 1.\n",
        "    else:\n",
        "        divisor = 128.\n",
        "        D_factor = 0.5\n",
        "\n",
        "    H_ = int(ceil(H / divisor) * divisor * D_factor)\n",
        "    W_ = int(ceil(W / divisor) * divisor * D_factor)\n",
        "\n",
        "    frame1_ = F.interpolate(frame1, (H_, W_), mode='bicubic')\n",
        "    frame3_ = F.interpolate(frame3, (H_, W_), mode='bicubic')\n",
        "\n",
        "    SBM = SBMNet(torch.cat((frame1_, frame3_), dim=1))[0]\n",
        "    SBM_= F.interpolate(SBM, scale_factor=4, mode='bilinear') * 20.0\n",
        "\n",
        "    frame2_1, Mask2_1 = warp(frame1_, SBM_ * (-1),  return_mask=True)\n",
        "    frame2_3, Mask2_3 = warp(frame3_, SBM_       ,  return_mask=True)\n",
        "\n",
        "    frame2_Anchor_ = (frame2_1 + frame2_3) / 2\n",
        "    frame2_Anchor = frame2_Anchor_ + 0.5 * (frame2_3 * (1-Mask2_1) + frame2_1 * (1-Mask2_3))\n",
        "\n",
        "    Z  = F.l1_loss(frame2_3, frame2_1, reduction='none').mean(1, True)\n",
        "    Z_ = F.interpolate(Z, scale_factor=0.25, mode='bilinear') * (-20.0)\n",
        "\n",
        "    ABM_bw, _ = ABMNet(torch.cat((frame2_Anchor, frame1_), dim=1), SBM*(-1), Z_.exp())\n",
        "    ABM_fw, _ = ABMNet(torch.cat((frame2_Anchor, frame3_), dim=1), SBM, Z_.exp())\n",
        "\n",
        "    SBM_     = F.interpolate(SBM, (H, W), mode='bilinear')   * 20.0\n",
        "    ABM_fw   = F.interpolate(ABM_fw, (H, W), mode='bilinear') * 20.0\n",
        "    ABM_bw   = F.interpolate(ABM_bw, (H, W), mode='bilinear') * 20.0\n",
        "\n",
        "    SBM_[:, 0, :, :] *= W / float(W_)\n",
        "    SBM_[:, 1, :, :] *= H / float(H_)\n",
        "    ABM_fw[:, 0, :, :] *= W / float(W_)\n",
        "    ABM_fw[:, 1, :, :] *= H / float(H_)\n",
        "    ABM_bw[:, 0, :, :] *= W / float(W_)\n",
        "    ABM_bw[:, 1, :, :] *= H / float(H_)\n",
        "\n",
        "    divisor = 8.\n",
        "    H_ = int(ceil(H / divisor) * divisor)\n",
        "    W_ = int(ceil(W / divisor) * divisor)\n",
        "\n",
        "    Syn_inputs = torch.cat((frame1, frame3, SBM_, ABM_fw, ABM_bw), dim=1)\n",
        "\n",
        "    Syn_inputs = F.interpolate(Syn_inputs, (H_,W_), mode='bilinear')\n",
        "    Syn_inputs[:, 6, :, :] *= float(W_) / W\n",
        "    Syn_inputs[:, 7, :, :] *= float(H_) / H\n",
        "    Syn_inputs[:, 8, :, :] *= float(W_) / W\n",
        "    Syn_inputs[:, 9, :, :] *= float(H_) / H\n",
        "    Syn_inputs[:, 10, :, :] *= float(W_) / W\n",
        "    Syn_inputs[:, 11, :, :] *= float(H_) / H \n",
        "\n",
        "    result = SynNet(Syn_inputs)\n",
        "\n",
        "    result = F.interpolate(result, (H,W), mode='bicubic')\n",
        "\n",
        "    save_image(result, output_frame_file_path)\n",
        "    input_frame += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FTyH0_dLJxD"
      },
      "source": [
        "# img -> video with ffmpeg\n",
        "# customize the ffmpeg command if needed\n",
        "# this is a very simple ffmpeg command, currently only creating video without sound\n",
        "%cd /content/data\n",
        "import cv2\n",
        "video = cv2.VideoCapture(\"/content/test.mkv\");\n",
        "fps = 2*video.get(cv2.CAP_PROP_FPS)\n",
        "%shell ffmpeg -y -r {fps} -f image2 -pattern_type glob -i '*.png' -crf 18 \"/content/output.mp4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4lqKnI5GMu9"
      },
      "source": [
        "# copy video back\n",
        "!cp /content/output.mp4 /content/drive/MyDrive/output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD5x4PK5MKWR"
      },
      "source": [
        "# delete output if needed\n",
        "%cd /content/\n",
        "!sudo rm -rf /content/data\n",
        "!sudo rm -rf /content/output.mp4\n",
        "!mkdir /content/data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}